# Descri√ß√£o do Projeto
Este projeto implementa tr√™s classificadores diferentes usando Redes Neurais Artificiais (RNA) em Python, explorando desde o Perceptron simples at√© MLPs mais complexos para diferentes tipos de dados.

## Objetivos de Aprendizado
Implementar um Perceptron para classifica√ß√£o multiclasse
Utilizar MLPClassifier para dados categ√≥ricos
Trabalhar com dados sint√©ticos gerados aleatoriamente
Avaliar modelos com m√©tricas de acur√°cia e matriz de confus√£o
Experimentar com hiperpar√¢metros de redes neurais

## Estrutura do Projeto
Exerc√≠cio 1: Classificador Perceptron para D√≠gitos
Base de dados: sklearn.datasets.load_digits() (1797 imagens de d√≠gitos)
Modelo: Perceptron do sklearn.linear_model
Tarefa: Classifica√ß√£o de d√≠gitos 0-9
Resultado: Acur√°cia e matriz de confus√£o

Exerc√≠cio 2: Classificador MLP para PlayTennis
Base de dados: PlayTennis.csv (dados categ√≥ricos)
Pr√©-processamento: LabelEncoder para vari√°veis categ√≥ricas
Modelo: MLPClassifier do sklearn.neural_network
Tarefa: Classifica√ß√£o bin√°ria (jogar/n√£o jogar t√™nis)
Hiperpar√¢metros ajustados: max_iter, alpha, tol

Exerc√≠cio 3: Classificador MLP para Dados Aleat√≥rios
Base de dados: Gerada com make_classification()
Caracter√≠sticas: 200 amostras, 4 features
Modelo: MLPClassifier com diferentes configura√ß√µes
Objetivo: Testar robustez em dados sint√©ticos

## Tecnologias Utilizadas
Python 3
scikit-learn: Perceptron, MLPClassifier, m√©tricas
pandas: Manipula√ß√£o de dados
NumPy: Opera√ß√µes num√©ricas

## Como Executar
1. Instala√ß√£o das Depend√™ncias
pip install scikit-learn pandas numpy

2. Executar o C√≥digo
python data_classifiers_RNA.py

## Resultados e M√©tricas
M√©tricas Implementadas
Acur√°cia (Score): clf.score(X, y)
Matriz de Confus√£o: confusion_matrix(y, y_pred)

## Hiperpar√¢metros Testados
- Perceptron
clf = Perceptron(tol=1e-3, random_state=0, max_iter=1000)

- MLPClassifier
clf = MLPClassifier(alpha=1e-05, tol=1e-4, random_state=0, max_iter=10000)
clf = MLPClassifier(alpha=1e-03, tol=1e-2, random_state=0, max_iter=9000)
clf = MLPClassifier(alpha=1e-03, tol=1e-3, random_state=0, max_iter=8000)

## An√°lise dos Modelos
- Perceptron
Vantagens: Simples, r√°pido, bom para problemas linearmente separ√°veis
Limita√ß√µes: N√£o resolve problemas n√£o-lineares complexos
Aplica√ß√£o: Classifica√ß√£o b√°sica de d√≠gitos

- MLP (Multi-Layer Perceptron)
Vantagens: Pode aprender rela√ß√µes n√£o-lineares, mais flex√≠vel
Configura√ß√£o: Permite ajuste de m√∫ltiplos hiperpar√¢metros
Aplica√ß√£o: Dados categ√≥ricos e sint√©ticos

## Experimenta√ß√£o
- Par√¢metros Ajust√°veis:
max_iter: N√∫mero m√°ximo de itera√ß√µes
alpha: Termo de regulariza√ß√£o
tol: Toler√¢ncia para parada precoce
random_state: Semente para reproducibilidade

- Impacto dos Hiperpar√¢metros:
alpha maior: Mais regulariza√ß√£o, menos overfitting
tol menor: Treinamento mais preciso, mas mais lento
max_iter maior: Mais chance de converg√™ncia

## Observa√ß√µes Importantes
- Problemas Identificados no C√≥digo:
Reutiliza√ß√£o de vari√°veis: O c√≥digo reusa X e y entre exerc√≠cios
Treinamento inconsistente: Algumas c√©lulas n√£o treinam o modelo MLP corretamente
Avalia√ß√£o nos dados de treino: As m√©tricas s√£o calculadas nos mesmos dados usados para treinar

- Melhorias Sugeridas:
Separar dados em treino/teste
Usar valida√ß√£o cruzada
Adicionar visualiza√ß√µes (gr√°ficos de aprendizado)
Testar diferentes arquiteturas de rede

## Conceitos de IA Aplicados
1. Aprendizado Supervisionado
Classifica√ß√£o com r√≥tulos conhecidos
Ajuste de pesos baseado em erro

2. Redes Neurais Artificiais
Perceptron: Camada √∫nica
MLP: M√∫ltiplas camadas (input, hidden, output)

3. Avalia√ß√£o de Modelos
M√©tricas quantitativas (acur√°cia)
An√°lise qualitativa (matriz de confus√£o)

#üë§ Autor
Projeto desenvolvido para a disciplina BSE038 - Intelig√™ncia Artificial, demonstrando habilidades em:
Implementa√ß√£o de algoritmos de IA
Pr√©-processamento de dados
Avalia√ß√£o de modelos de classifica√ß√£o
Experimenta√ß√£o com hiperpar√¢metros

## Pr√≥ximos Passos
Implementar valida√ß√£o cruzada
Adicionar visualiza√ß√£o dos resultados
Testar com mais bases de dados
Comparar com outros classificadores (SVM, Random Forest)
