# üìä Processamento de Dados do ENEM 1998 com Dask
## Descri√ß√£o
Este projeto realiza o processamento e padroniza√ß√£o dos microdados do ENEM 1998 utilizando a biblioteca Dask para manipula√ß√£o eficiente de grandes volumes de dados. O c√≥digo transforma dados brutos em um formato estruturado e padronizado para an√°lise.

## Objetivos
1. Processar grandes volumes de dados do ENEM 1998 de forma eficiente
2. Renomear e padronizar vari√°veis para melhor compreens√£o
3. Converter c√≥digos categ√≥ricos em r√≥tulos descritivos
4. Exportar dados em formatos otimizados (Parquet) para an√°lise posterior

## Tecnologias Utilizadas
Python 3
Dask: Processamento paralelo de grandes datasets
PyArrow: Formato Parquet para armazenamento eficiente
Pandas: Manipula√ß√£o auxiliar de dados

## Estrutura do Processamento
1. Carregamento de Dados
Leitura do arquivo CSV original com dask.dataframe
Tratamento de valores faltantes com assume_missing=True
Dataset: MICRODADOS_ENEM_1998.csv (~500k+ registros)

2. Sele√ß√£o de Vari√°veis
Filtro de 60 colunas relevantes, incluindo:
Dados demogr√°ficos (idade, sexo, estado)
Desempenho (notas objetivas e reda√ß√£o)
Question√°rio socioecon√¥mico (56 vari√°veis)

3. Padroniza√ß√£o Completa
Renomea√ß√£o de Colunas
Mapeamento de Valores Categ√≥ricos

4. Tipagem de Dados
Categ√≥ricas: 56 vari√°veis convertidas para tipo category
Num√©ricas: Notas e ano mantidas como int64
Otimiza√ß√£o de mem√≥ria e desempenho

5. Exporta√ß√£o
Formato Parquet (recomendado): enem_1998/
Compress√£o Snappy para efici√™ncia
Valida√ß√£o da escrita/leitura

## Como Executar
Instala√ß√£o:
pip install "dask[complete]" pandas pyarrow

Execu√ß√£o:
python enem_1998.py


## Dados Processados
### Vari√°veis Principais
Demogr√°ficas: Idade, sexo, UF, ra√ßa/cor, estado civil
Educacionais: Escolaridade dos pais, tipo de escola, conclus√£o do ensino m√©dio
Socioecon√¥micas: Renda, trabalho, bens dom√©sticos
Interesses: Acompanhamento de pol√≠tica, esportes, cultura
Desempenho: Notas objetivas e de reda√ß√£o

### Sa√≠das Geradas
1. DataFrame Padronizado
60 colunas renomeadas
Valores descritivos em portugu√™s
Tipos otimizados

2. Arquivos Parquet
Particionados automaticamente
Comprimidos (snappy)
Prontos para an√°lise no BigQuery, Spark, etc.

3. Valida√ß√µes
Contagem de linhas/colunas
Verifica√ß√£o de tipos de dados
Distribui√ß√£o de valores por vari√°vel

### Insights do C√≥digo
Boas Pr√°ticas Implementadas
Processamento Lazy: Dask s√≥ computa quando necess√°rio
Otimiza√ß√£o de Mem√≥ria: Uso de tipos categ√≥ricos
Padroniza√ß√£o Consistente: Dicion√°rios centralizados
Valida√ß√£o: Verifica√ß√£o ap√≥s escrita

### Pontos de Destaque
Escalabilidade: Processa milh√µes de registros com efici√™ncia
Reprodutibilidade: Transforma√ß√µes completamente documentadas
Interoperabilidade: Sa√≠da compat√≠vel com m√∫ltiplas ferramentas

## Aplica√ß√µes
1. An√°lise Educacional
Correla√ß√£o entre fatores socioecon√¥micos e desempenho
Perfil dos candidatos do primeiro ENEM
Evolu√ß√£o hist√≥rica do exame
2. Ci√™ncia de Dados
Exemplo de ETL com Dask
Padroniza√ß√£o de dados categ√≥ricos
Otimiza√ß√£o de pipelines de dados

## Pr√≥ximos Passos Poss√≠veis
1. An√°lise Explorat√≥ria
Estat√≠sticas descritivas
Visualiza√ß√µes gr√°ficas
Correla√ß√µes entre vari√°veis

2. Pipeline Completo
Download autom√°tico dos dados
Processamento em lote para m√∫ltiplos anos
Upload para BigQuery/Data Warehouse

3. Aplica√ß√µes de ML
Predi√ß√£o de notas
Clusteriza√ß√£o de perfis
An√°lise de fatores de sucesso


